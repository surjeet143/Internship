{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import lxml\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a general function to save the dataframe as CSV file\n",
    "def save_csv(df, name):\n",
    "    if name[-4:] == \".csv\":\n",
    "        df.to_csv(name)\n",
    "    else:\n",
    "        name = name + \".csv\"\n",
    "        df.to_csv(name)\n",
    "    print(\"your file\",name, \"has been saved\")\n",
    "    df.head()\n",
    "    #print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. fetching the headertags from Wikipedia mainpage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching the data from the webpage...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From today's featured list</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     header tags\n",
       "0  From today's featured article\n",
       "1               Did you know ...\n",
       "2                    In the news\n",
       "3                    On this day\n",
       "4     From today's featured list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def webscrap_wiki(link, csv_name):\n",
    "    # fetching the wbpage\n",
    "    print(\"fetching the data from the webpage...\")\n",
    "    page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "    soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    # extracting the h1 tags\n",
    "    h2_tags = soup.select(\"h2.mp-h2 span\")\n",
    "    h2_tags = [tag.text for tag in h2_tags]\n",
    "    h2_tags = [tags for tags in h2_tags if len(tags)>0]\n",
    "    \n",
    "    # extracting the h2 tags\n",
    "    h3_tags = soup.select(\"h3.vector-menu-heading span\")\n",
    "    h3_tags = [h3tag.text for h3tag in h3_tags]\n",
    "    h3_tags = [htags for htags in h3_tags if len(htags)>0]\n",
    "    \n",
    "    # concatenate h2 and h3 list\n",
    "    final_tags = h2_tags + h3_tags\n",
    "    \n",
    "    # creating a dictionary of all the list created above\n",
    "    dict = {'header tags': final_tags}\n",
    "    df = pd.DataFrame(dict)\n",
    "    return df.head()\n",
    "    \n",
    "    # df can be saved as csv file by executing the function below\n",
    "    #save_csv(df, \"wikipedia headertags\")\n",
    "\n",
    "webscrap_wiki(\"https://en.wikipedia.org/wiki/Main_Page\", \"Wikipedia headertags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. IMDB's top rated 100 movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching the data from the webpage...\n",
      "fetching movie names...\n",
      "fetching year of release...\n",
      "fetching movie rating...\n",
      "creating dataframe...\n",
      "saving dataframe as CSV...\n",
      "your file top_100_movies.csv has been saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie name</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 movie name  year  rating\n",
       "0  The Shawshank Redemption  1994    9.22\n",
       "1             The Godfather  1972    9.15\n",
       "2    The Godfather: Part II  1974    8.98\n",
       "3           The Dark Knight  2008    8.97\n",
       "4              12 Angry Men  1957    8.94"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining function to web scrape the web page\n",
    "# paste the link in the webscrap function\n",
    "def webscrap_IMDB(link, csv_name):\n",
    "    # fetching the wbpage\n",
    "    print(\"fetching the data from the webpage...\")\n",
    "    page = requests.get(link)\n",
    "    soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "    # extracting the movietags and innertags\n",
    "    movietags = soup.select(\"td.titleColumn\")\n",
    "    inner_movietags = soup.select(\"td.titleColumn a\")\n",
    "    # extracting the name of the movie\n",
    "    print(\"fetching movie names...\")\n",
    "    movie_names = [movie.text for movie in inner_movietags]\n",
    "    # extracting the actors including the director\n",
    "    # year of release of movie\n",
    "    print(\"fetching year of release...\")\n",
    "    years = [movie.text.split()[-1].replace(\")\",\"\").replace(\"(\",\"\") for movie in movietags]\n",
    "    # imdb rating tag of the movie \n",
    "    rating_tags = soup.select(\"td.posterColumn span[name = ir]\")\n",
    "    # imdb rating of movie\n",
    "    print(\"fetching movie rating...\")\n",
    "    rating = [round(float(movie['data-value']),2) for movie in rating_tags]\n",
    "    # creating a dictionary of all the list created above\n",
    "    dict = {'movie name': movie_names, \"year\": years,'rating': rating} \n",
    "    # converting the dictionary into dataframe\n",
    "    df = pd.DataFrame(dict)\n",
    "    df[\"year\"] = df[\"year\"].apply(pd.to_numeric)\n",
    "    df_100 = df.head(100)\n",
    "    print(\"creating dataframe...\")\n",
    "    print(\"saving dataframe as CSV...\")\n",
    "    save_csv(df_100, csv_name)\n",
    "    return df_100.head()\n",
    "    #return (df_100)\n",
    "webscrap_IMDB(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250/\", \"top_100_movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. IMDB's top 100 indian movies**\n",
    "Same algorithm used in above problem can be used to scrap the top 100 indian movies. Just replace the link of top 100 movies with the link of top indian movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching the data from the webpage...\n",
      "fetching movie names...\n",
      "fetching year of release...\n",
      "fetching movie rating...\n",
      "creating dataframe...\n",
      "saving dataframe as CSV...\n",
      "your file top_100_indian_movies.csv has been saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie name</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie name  year  rating\n",
       "0            Nayakan  1987    8.49\n",
       "1         Anbe Sivam  2003    8.48\n",
       "2  Pariyerum Perumal  2018    8.48\n",
       "3  C/o Kancharapalem  2018    8.47\n",
       "4            Golmaal  1979    8.47"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webscrap_IMDB('''https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_\n",
    "rd_p=2e9dfa9b-3e4d-4d39-acd2-8af11f252a59&pf_rd_r=RFJGXDAT1JGH01JGF9CY&pf_rd_s=right-5&pf_\n",
    "rd_t=15506&pf_rd_i=top&ref_=chttp_india_tr_rhs_1''', \"top_100_indian_movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. getting bookname, author, genre, and review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching page...\n",
      "getting book names...\n",
      "getting book author...\n",
      "getting book genre...\n",
      "getting review...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book name</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Lincoln Highway</td>\n",
       "      <td>Amor Towles</td>\n",
       "      <td>Fiction / Historical Fiction</td>\n",
       "      <td>“I guess you haven’t had your adventure yet,” ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Light From Uncommon Stars</td>\n",
       "      <td>Ryka Aoki</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Science Fiction</td>\n",
       "      <td>What is it with the devil and violinists? Seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chasing Ghosts</td>\n",
       "      <td>Marc Hartzman</td>\n",
       "      <td>Nonfiction / History / Spirituality</td>\n",
       "      <td>As long as there has been death, there have be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr. Watson's Chickens</td>\n",
       "      <td>Jarrett Dapier,  Andrea Tsurumi</td>\n",
       "      <td>Children's / Picture Book</td>\n",
       "      <td>Mr. Watson and Mr. Nelson live together in a “...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Calling for Charlie Barnes</td>\n",
       "      <td>Joshua Ferris</td>\n",
       "      <td>Fiction / Family Drama</td>\n",
       "      <td>How does one sum up the arc of a long life? Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       book name                           author  \\\n",
       "0            The Lincoln Highway                      Amor Towles   \n",
       "1      Light From Uncommon Stars                        Ryka Aoki   \n",
       "2                 Chasing Ghosts                    Marc Hartzman   \n",
       "3          Mr. Watson's Chickens  Jarrett Dapier,  Andrea Tsurumi   \n",
       "4   A Calling for Charlie Barnes                    Joshua Ferris   \n",
       "\n",
       "                                         genre  \\\n",
       "0                 Fiction / Historical Fiction   \n",
       "1  Science Fiction & Fantasy / Science Fiction   \n",
       "2          Nonfiction / History / Spirituality   \n",
       "3                    Children's / Picture Book   \n",
       "4                       Fiction / Family Drama   \n",
       "\n",
       "                                             reviews  \n",
       "0  “I guess you haven’t had your adventure yet,” ...  \n",
       "1  What is it with the devil and violinists? Seem...  \n",
       "2  As long as there has been death, there have be...  \n",
       "3  Mr. Watson and Mr. Nelson live together in a “...  \n",
       "4  How does one sum up the arc of a long life? Th...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookslink = \"https://bookpage.com/reviews\"\n",
    "\n",
    "def book_rev(link, csv_name):\n",
    "    print(\"fetching page...\")\n",
    "    page = requests.get(bookslink)\n",
    "    soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    # extracting book names\n",
    "    print(\"getting book names...\")\n",
    "    book_names = soup.select(\"h4\")\n",
    "    book_names = [hdtag.text.strip().replace(\"★\",\"\") for hdtag in book_names]\n",
    "    \n",
    "    print(\"getting book author...\")\n",
    "    author = soup.select(\"p.sans.bold\")\n",
    "    author = [author.text.strip() for author in author]\n",
    "    \n",
    "    print(\"getting book genre...\")\n",
    "    genre = soup.select(\"p.genre-links.hidden-phone\")\n",
    "    genre = [genre.text.strip().replace(\"\\n\",\"\") for genre in genre]\n",
    "    \n",
    "    def get_rev(rev_link):\n",
    "        rl_page = requests.get(rev_link)\n",
    "        soup_rl = bs.BeautifulSoup(rl_page.text, \"html.parser\")\n",
    "        review = soup_rl.select(\"div.span7 p\")\n",
    "        review = [review.text.replace(\"\\n\",'') for review in review]\n",
    "        r=\"\"\n",
    "        for rev in review:\n",
    "            r = r + rev\n",
    "        return r\n",
    "    \n",
    "    print(\"getting review...\")\n",
    "    review_link = soup.select(\"div.read-full a\")\n",
    "    review_link = ['http://bookpage.com'+rev.get('href') for rev in review_link]\n",
    "    reviews = [get_rev(rev) for rev in review_link]\n",
    "    \n",
    "    #creating dictionary and dataframe\n",
    "    dict = {\"book name\": book_names, \"author\": author, \"genre\": genre, \"reviews\": reviews}\n",
    "    review_df = pd.DataFrame(dict)\n",
    "    df = review_df.head()\n",
    "    return df\n",
    "    save_csv(review_df, csv_name)\n",
    "book_rev(bookslink, \"books_review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(i). scraping top 10 ODI terms with matches, points and ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting details of teams...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>28</td>\n",
       "      <td>3,244</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,624</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>25</td>\n",
       "      <td>2,459</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team matches points ratings\n",
       "0   New Zealand      17  2,054     121\n",
       "1       England      32  3,793     119\n",
       "2     Australia      28  3,244     116\n",
       "3         India      32  3,624     113\n",
       "4  South Africa      25  2,459      98"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_link = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "\n",
    "def top_odi(link, csv_name):\n",
    "    print(\"getting details of teams...\")\n",
    "    #getting details of top team\n",
    "    \n",
    "    page = requests.get(link)\n",
    "    soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "    team = soup.select(\"span.u-hide-phablet\")\n",
    "    team = [team.text for team in team if len(team.text)>0]\n",
    "    matches = [soup.select(\"td.rankings-block__banner--matches\")[0].text]\n",
    "    points = [soup.select(\"td.rankings-block__banner--points\")[0].text]\n",
    "    rating = [soup.select(\"td.rankings-block__banner--rating.u-text-right\")[0].text.strip()]\n",
    "\n",
    "    #getting details of remaining teams\n",
    "    ratings = soup.select(\"td.table-body__cell.u-text-right.rating\")\n",
    "    ratings = [rating.text for rating in ratings]\n",
    "    ratings = rating + ratings\n",
    "\n",
    "    matches_points = soup.select(\"td.table-body__cell.u-center-text\")\n",
    "    for i in range(len(matches_points)):\n",
    "        if i%2==0:\n",
    "            matches.append(matches_points[i].text)\n",
    "        else:\n",
    "            points.append(matches_points[i].text)\n",
    "    \n",
    "    dict = {\"team\":team[0:10], \"matches\":matches[0:10], \"points\":points[0:10], \"ratings\": ratings[0:10]}\n",
    "    odi_df = pd.DataFrame(dict)\n",
    "    df = odi_df.head()\n",
    "    return df\n",
    "    save_csv(odi_df, csv_name)\n",
    "    \n",
    "top_odi(odi_link, \"top_odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(ii). top 10 ODI batsman with their team and ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting details of top batsman...\n",
      "your file top_odi_bat.csv has been saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top batsmen</th>\n",
       "      <th>nationality</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    top batsmen nationality ratings\n",
       "0    Babar Azam         PAK     873\n",
       "1   Virat Kohli         IND     844\n",
       "2  Rohit Sharma         IND     813\n",
       "3   Ross Taylor          NZ     801\n",
       "4   Aaron Finch         AUS     779"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_link_bat= \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\"\n",
    "\n",
    "def top_odi_bat(link, csv_name):\n",
    "    print(\"getting details of top batsman...\")\n",
    "    page = requests.get(link)\n",
    "    soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    #extracting top most batsman\n",
    "    top1 = soup.select(\"div.rankings-block__banner--name\")\n",
    "    #extracting the remaining nine batsman\n",
    "    top = soup.select(\"td.table-body__cell.name a\")[0:9]\n",
    "    top_bats = [top1[0].text] + [top.text for top in top]\n",
    "\n",
    "    top1 = soup.select(\"div.rankings-block__banner--name\")\n",
    "    top = soup.select(\"td.table-body__cell.name a\")[0:9]\n",
    "    top_bats = [top1[0].text] + [top.text for top in top]\n",
    "\n",
    "    top_nat1 = soup.select('div.rankings-block__banner--nationality')[0].text.strip()\n",
    "    top_nat = soup.select(\"td.table-body__cell.nationality-logo span.table-body__logo-text\")[0:9]\n",
    "    top_nats = [top_nat1] + [top.text for top in top_nat]\n",
    "\n",
    "    top_rat1 = soup.select('div.rankings-block__banner--rating')[0].text.strip()\n",
    "    top_rat = soup.select(\"td.table-body__cell.u-text-right.rating\")[0:9]\n",
    "    top_rats = [top_rat1] + [rat.text for rat in top_rat]\n",
    "    \n",
    "    dict = {\"top batsmen\":top_bats, \"nationality\": top_nats, \"ratings\":top_rats}\n",
    "    bat_df = pd.DataFrame(dict)\n",
    "    save_csv(bat_df, csv_name)\n",
    "    df = bat_df.head()\n",
    "    return df\n",
    "top_odi_bat(odi_link_bat, \"top_odi_bat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(iii). scraping top 10 ODI bowlers with their team and ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top bowler</th>\n",
       "      <th>nationality</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         top bowler nationality ratings\n",
       "0       Trent Boult          NZ     737\n",
       "1    Josh Hazlewood         AUS     709\n",
       "2  Mujeeb Ur Rahman         AFG     708\n",
       "3      Chris Woakes         ENG     700\n",
       "4      Mehedi Hasan         BAN     692"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this i haven't defined functions for scraping and didn't saved data as CSV file\n",
    "odi_top_bat = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\"\n",
    "page = requests.get(odi_top_bat)\n",
    "soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "top_bowl1 = soup.select(\"div.rankings-block__banner--name\")\n",
    "top_bowl = soup.select(\"td.table-body__cell.name a\")[9:18]\n",
    "top_bowls = [top_bowl1[1].text] + [top.text for top in top_bowl]\n",
    "\n",
    "top_bowl_nat1 = soup.select('div.rankings-block__banner--nationality')[1].text.replace(\"\\n\",'')\n",
    "top_bowl_nat = soup.select(\"td.table-body__cell.nationality-logo span.table-body__logo-text\")[9:18]\n",
    "top_bowl_nats = [top_bowl_nat1] + [top.text for top in top_bowl_nat]\n",
    "\n",
    "top_bowl_rat1 = soup.select('div.rankings-block__banner--rating')[1].text.replace(\"\\n\",'')\n",
    "top_bowl_rat = soup.select(\"td.table-body__cell.u-text-right.rating\")[9:18]\n",
    "top_bowl_rats = [top_bowl_rat1] + [top.text for top in top_bowl_rat]\n",
    "    \n",
    "dict = {\"top bowler\":top_bowls, \"nationality\": top_bowl_nats, \"ratings\":top_bowl_rats}\n",
    "bowl_df = pd.DataFrame(dict)\n",
    "bowl_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(i) Fetching top ODI women team. The same code can work to fetching women ODI teams.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting details of teams...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,379</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>25</td>\n",
       "      <td>2,983</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>29</td>\n",
       "      <td>3,390</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>26</td>\n",
       "      <td>2,934</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26</td>\n",
       "      <td>2,392</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team matches points ratings\n",
       "0     Australia      21  3,379     161\n",
       "1       England      25  2,983     119\n",
       "2  South Africa      29  3,390     117\n",
       "3         India      26  2,934     113\n",
       "4   New Zealand      26  2,392      92"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the code written for ODI men team can work for ODI women team also. Just replace the link of ODI women teams page\n",
    "top_odi('https://www.icc-cricket.com/rankings/womens/team-rankings/odi', \"top_odi_women\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(ii) fetching top women batsman for ODI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching the player details...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top woman batsman</th>\n",
       "      <th>nationality</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top woman batsman nationality ratings\n",
       "0        Lizelle Lee          SA     761\n",
       "1       Alyssa Healy         AUS     750\n",
       "2        Mithali Raj         IND     738\n",
       "3     Tammy Beaumont         ENG     728\n",
       "4  Amy Satterthwaite          NZ     717"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_bat_link = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "def w_top_bat(url, csv_name):\n",
    "    print(\"fetching the player details...\")\n",
    "    page = requests.get(url)\n",
    "    soup = bs.BeautifulSoup(page.text, \"lxml\")\n",
    "\n",
    "    # fetching the details of first player\n",
    "    top_1_bat = soup.select(\"div.rankings-block__banner--name-large\")[0].text\n",
    "    top_1_wbat_nat = soup.select('div.rankings-block__banner--nationality')[0].text.strip()\n",
    "    top_1_wbat_rat = soup.select(\"div.rankings-block__banner--rating\")[0].text.strip()\n",
    "\n",
    "    # fetching the details of remaining batsman\n",
    "    top_wbat = soup.select(\"td.table-body__cell.rankings-table__name.name\") \n",
    "    top_wbat = [top.text.strip() for top in top_wbat]\n",
    "    top_wnat = soup.select(\"td.table-body__cell.nationality-logo.rankings-table__team\")\n",
    "    top_wnat = [top.text.strip() for top in top_wnat]\n",
    "    top_wrat = soup.select(\"td.table-body__cell.rating\")\n",
    "    top_wrat = [top.text.strip() for top in top_wrat]\n",
    "\n",
    "    dict = {\"top woman batsman\":[top_1_bat]+top_wbat, \"nationality\": [top_1_wbat_nat]+top_wnat, \"ratings\":[top_1_wbat_rat]+top_wrat}\n",
    "    wbat_df = pd.DataFrame(dict)\n",
    "    return wbat_df.head(5)\n",
    "w_top_bat(women_bat_link, \"women_top_bat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(iii) Fetching the top women bowler in ODI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined to fetch the top women batsman can fetch the top women bowler with the apprpriate link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_top_bowl = w_top_bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching the player details...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top woman batsman</th>\n",
       "      <th>nationality</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top woman batsman nationality ratings\n",
       "0      Jess Jonassen         AUS     760\n",
       "1     Jhulan Goswami         IND     727\n",
       "2       Megan Schutt         AUS     717\n",
       "3     Marizanne Kapp          SA     715\n",
       "4  Sophie Ecclestone         ENG     701"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowl_url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "w_top_bowl(bowl_url, \"women_top_bowler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top woman batsman</th>\n",
       "      <th>nationality</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top woman batsman nationality ratings\n",
       "0      Jess Jonassen         AUS     760\n",
       "1     Jhulan Goswami         IND     727\n",
       "2       Megan Schutt         AUS     717\n",
       "3     Marizanne Kapp          SA     715\n",
       "4  Sophie Ecclestone         ENG     701"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(bowl_url)\n",
    "soup = bs.BeautifulSoup(page.text, \"lxml\")\n",
    "\n",
    "# fetching the details of first player\n",
    "top_1_bat = soup.select(\"div.rankings-block__banner--name-large\")[0].text\n",
    "top_1_wbat_nat = soup.select('div.rankings-block__banner--nationality')[0].text.strip()\n",
    "top_1_wbat_rat = soup.select(\"div.rankings-block__banner--rating\")[0].text.strip()\n",
    "\n",
    "# fetching the details of remaining batsman\n",
    "top_wbat = soup.select(\"td.table-body__cell.rankings-table__name.name\") \n",
    "top_wbat = [top.text.strip() for top in top_wbat]\n",
    "top_wnat = soup.select(\"td.table-body__cell.nationality-logo.rankings-table__team\")\n",
    "top_wnat = [top.text.strip() for top in top_wnat]\n",
    "top_wrat = soup.select(\"td.table-body__cell.rating\")\n",
    "top_wrat = [top.text.strip() for top in top_wrat]\n",
    "\n",
    "dict = {\"top woman batsman\":[top_1_bat]+top_wbat, \"nationality\": [top_1_wbat_nat]+top_wnat, \"ratings\":[top_1_wbat_rat]+top_wrat}\n",
    "wbat_df = pd.DataFrame(dict)\n",
    "wbat_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **7 Fetching the mobile phones below Rs. 20000 from amazon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting links for all products for a given page number\n",
    "def get_links(link):\n",
    "    product_links = []\n",
    "    img_links = []\n",
    "    \n",
    "    page_link = link\n",
    "    page = requests.get(page_link)\n",
    "    soup = bs.BeautifulSoup(page.text, \"lxml\")\n",
    "    #print(len(soup))\n",
    "    links_a = soup.select(\"h2 a\")\n",
    "    image_link = soup.select('img.s-image')\n",
    "    img_links = img_links+[link.get(\"src\") for link in image_link]\n",
    "    product_links = product_links+['https://amazon.in'+link.get('href') for link in links_a]\n",
    "    #page_link = \"https://amazon.in\" + soup.select(\"ul.a-pagination li.a-normal a\")[0].get(\"href\")\n",
    "    return img_links, product_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the title, price and rating of products\n",
    "def title_rating_price(soup):\n",
    "    #price = float(soup.find('span',id=\"priceblock_ourprice\").text.replace(\"₹\",\"\").replace(\",\",\"\"))\n",
    "    price = float(soup.select(\"td.a-span12 span\")[0].text.replace(\"₹\",\"\").replace(\",\",\"\"))\n",
    "    if price<20000:\n",
    "        title = soup.select(\"h1 span\")[0].text.replace(\"\\n\",\"\").split(\"(\")[0]\n",
    "        rating = float(soup.select(\"span.a-icon-alt\")[0].text[:3])\n",
    "        price = float(soup.select(\"td.a-span12 span\")[0].text.replace(\"₹\",\"\").replace(\",\",\"\"))\n",
    "        #price = float(soup.find('span',id=\"priceblock_ourprice\").text.replace(\"₹\",\"\").replace(\",\",\"\"))\n",
    "        form_factor = ab = soup.select(\"td.a-span9 span\")[3].text\n",
    "        return title, rating, price, form_factor\n",
    "    return 0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching the data and creating the dataframe\n",
    "HEADERS ={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36\"}\n",
    "def amazon(n_page):\n",
    "    titles = []\n",
    "    img_url = []\n",
    "    prices = []\n",
    "    ratings = []\n",
    "    form_fact = []\n",
    "    page_link2 = 'https://www.amazon.in/s?i=electronics&rh=n%3A1389401031&fs=true&page=2&qid=1632398261&ref=sr_pg_1'\n",
    "    for i in range(n_page):\n",
    "        page1 = requests.get(page_link2, headers = HEADERS)\n",
    "        soup = bs.BeautifulSoup(page1.text, \"html.parser\")\n",
    "        image_link, product_link = get_links(page_link2)\n",
    "        while len(image_link)==0:\n",
    "            image_link, product_link = get_links(page_link2)\n",
    "        while len(soup.select(\"ul.a-pagination li.a-last a\")) == 0:\n",
    "            page_link2= \"https://amazon.in\"+soup.select(\"ul.a-pagination li.a-last a\")[0].get(\"href\")\n",
    "        print(\"images\", len(image_link),\"fetched\")\n",
    "        for j in range(len(image_link)):\n",
    "            #print(\"fetching the data for\",i,j)\n",
    "            #print(product_link[j])\n",
    "            page = requests.get(product_link[j], headers = HEADERS)\n",
    "            soup = bs.BeautifulSoup(page.content, \"html\")\n",
    "            title, rating, price, form_factor = title_rating_price(soup)\n",
    "            titles.append(title)\n",
    "            img_url.append(image_link[j])\n",
    "            prices.append(price)\n",
    "            ratings.append(rating)\n",
    "            form_fact.append(form_factor)\n",
    "\n",
    "    dict = {\"title\": titles,\"image link\": img_url, \"price\":prices, \"form factor\":form_fact}\n",
    "    df = pd.DataFrame(dict)\n",
    "    df = df[df[\"form factor\"]==\"Smartphone\"]\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images 24 fetched\n",
      "images 24 fetched\n",
      "images 24 fetched\n",
      "images 24 fetched\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>image link</th>\n",
       "      <th>price</th>\n",
       "      <th>form factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Redmi 9</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Redmi Note 10 Pro</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81aQWPoGdO...</td>\n",
       "      <td>19999.0</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Redmi 9</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Redmi Note 10 Pro</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81aQWPoGdO...</td>\n",
       "      <td>19999.0</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Redmi 9</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>10999.0</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title                                         image link  \\\n",
       "2             Redmi 9   https://m.media-amazon.com/images/I/71A9Vo1Bat...   \n",
       "15  Redmi Note 10 Pro   https://m.media-amazon.com/images/I/81aQWPoGdO...   \n",
       "26            Redmi 9   https://m.media-amazon.com/images/I/71A9Vo1Bat...   \n",
       "39  Redmi Note 10 Pro   https://m.media-amazon.com/images/I/81aQWPoGdO...   \n",
       "50            Redmi 9   https://m.media-amazon.com/images/I/71A9Vo1Bat...   \n",
       "\n",
       "      price form factor  \n",
       "2   10999.0  Smartphone  \n",
       "15  19999.0  Smartphone  \n",
       "26  10999.0  Smartphone  \n",
       "39  19999.0  Smartphone  \n",
       "50  10999.0  Smartphone  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_link = 'https://www.amazon.in/s?i=electronics&rh=n%3A1389401031&fs=true&page=2&qid=1632398261&ref=sr_pg_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8 Fetching weather data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period name</th>\n",
       "      <th>short dec</th>\n",
       "      <th>temp</th>\n",
       "      <th>decription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overnight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 59 °F</td>\n",
       "      <td>Mostly clear, with a low around 59. Southwest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 79 °F</td>\n",
       "      <td>Sunny, with a high near 79. Light west southw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SundayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Partly cloudy, with a low around 57. West sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 75 °F</td>\n",
       "      <td>Mostly sunny, with a high near 75. West wind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MondayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Partly cloudy, with a low around 56. West sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   period name      short dec         temp  \\\n",
       "0    Overnight   Mostly Clear   Low: 59 °F   \n",
       "1       Sunday          Sunny  High: 79 °F   \n",
       "2  SundayNight  Partly Cloudy   Low: 57 °F   \n",
       "3       Monday   Mostly Sunny  High: 75 °F   \n",
       "4  MondayNight  Partly Cloudy   Low: 56 °F   \n",
       "\n",
       "                                          decription  \n",
       "0   Mostly clear, with a low around 59. Southwest...  \n",
       "1   Sunny, with a high near 79. Light west southw...  \n",
       "2   Partly cloudy, with a low around 57. West sou...  \n",
       "3   Mostly sunny, with a high near 75. West wind ...  \n",
       "4   Partly cloudy, with a low around 56. West sou...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_link = \"https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168#.YVNq_bgza00\"\n",
    "\n",
    "def fetch_weather(weather_link):\n",
    "    page = requests.get(weather_link)\n",
    "    soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "    p_name = soup.select(\"li.forecast-tombstone p.period-name\")\n",
    "    period_names = [pn.text for pn in p_name]\n",
    "    short_dec = soup.select(\"li p.short-desc\")\n",
    "    short_decs = [sd.text for sd in short_dec]\n",
    "    desc = soup.select(\"p img\")\n",
    "    desc = [d.get(\"alt\").split(\":\")[1] for d in desc]\n",
    "    temp = soup.select('li p.temp')\n",
    "    temps = [temp.text for temp in temp]\n",
    "    dict = {\"period name\":period_names, \"short dec\":short_decs, \"temp\":temps, \"decription\": desc}\n",
    "    df = pd.DataFrame(dict)\n",
    "    return df.head()\n",
    "\n",
    "fetch_weather(weather_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9 Fetching data from internshala**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job title</th>\n",
       "      <th>company</th>\n",
       "      <th>CTC</th>\n",
       "      <th>apply date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>NSE Academy</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>31 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Management Trainee - Sales</td>\n",
       "      <td>CEAT Limited</td>\n",
       "      <td>5 LPA</td>\n",
       "      <td>29 Oct' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Development Manager (Digital Marketin...</td>\n",
       "      <td>Graygraph Technologies LLC</td>\n",
       "      <td>4.2 - 4.8 LPA</td>\n",
       "      <td>1 Nov' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corporate Sales Executive</td>\n",
       "      <td>Samvedna Senior Care Private Limited</td>\n",
       "      <td>3.25 - 4 LPA</td>\n",
       "      <td>1 Nov' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Content Writer</td>\n",
       "      <td>High School Moms</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>1 Nov' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job title  \\\n",
       "0                     Business Development Executive   \n",
       "1                         Management Trainee - Sales   \n",
       "2  Business Development Manager (Digital Marketin...   \n",
       "3                          Corporate Sales Executive   \n",
       "4                              Junior Content Writer   \n",
       "\n",
       "                                company            CTC  apply date  \n",
       "0                           NSE Academy          3 LPA  31 Oct' 21  \n",
       "1                          CEAT Limited          5 LPA  29 Oct' 21  \n",
       "2            Graygraph Technologies LLC  4.2 - 4.8 LPA   1 Nov' 21  \n",
       "3  Samvedna Senior Care Private Limited   3.25 - 4 LPA   1 Nov' 21  \n",
       "4                      High School Moms    3 - 3.2 LPA   1 Nov' 21  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internshala_link = \"https://internshala.com/fresher-jobs\"\n",
    "def jobs_data(internshala_link):\n",
    "    page1 = requests.get(internshala_link)\n",
    "    soup1 = bs.BeautifulSoup(page1.text, \"html.parser\")\n",
    "    job_title = soup1.select(\"div.company div.heading_4_5.profile a\")\n",
    "    job_title = [job.text.strip() for job in job_title]\n",
    "    company = soup1.select(\"div.company div.heading_6.company_name a\")\n",
    "    company = [company.text.strip() for company in company]\n",
    "    r = soup1.select(\"div.internship_other_details_container div.other_detail_item div.item_body\")\n",
    "    list = [ra.text.strip() for ra in r]\n",
    "    CTC = [list[i+1] for i in range(len(list)) if i%3==0 ]\n",
    "    apply_date = [list[i+2] for i in range(len(list)) if i%3==0 ]\n",
    "    dict = {\"job title\":job_title, \"company\": company, \"CTC\": CTC, \"apply date\": apply_date}\n",
    "    df = pd.DataFrame(dict)\n",
    "    return df.head()\n",
    "\n",
    "jobs_data(internshala_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10 fetching data from nobroker.com for a location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HEADERS ={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\\\n",
    "#(KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36\"}\n",
    "\n",
    "banglore_url = 'https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0'\n",
    "delhi_url = 'https://www.nobroker.in/property/sale/delhi/Sarita%20Vihar?searchParam=W3sibGF0IjoyOC41MzA3ODEyLCJsb24iOjc3LjI5Mzk5ODEsInBsYWNlSWQiOiJDaElKdTNJNlJxbm1ERGtSQUVraFFCY3QxU1UiLCJwbGFjZU5hbWUiOiJTYXJpdGEgVmloYXIifV0=&radius=2.0'\n",
    "mumbai_url = 'https://www.nobroker.in/property/sale/mumbai/Film%20City%20Complex?searchParam=W3sibGF0IjoxOS4xNTk0MDM5LCJsb24iOjcyLjg4ODQ2OTgsInBsYWNlSWQiOiJDaElKcnhmT3lZMjM1enNSVkhSTG1vc1d2bHciLCJwbGFjZU5hbWUiOiJGaWxtIENpdHkgQ29tcGxleCJ9XQ==&radius=2.0'\n",
    "def no_broker(link, csv_name):\n",
    "    print(\"ferching data from nobroker\")\n",
    "    page = requests.get(link)\n",
    "    soup = bs.BeautifulSoup(page.content, \"lxml\")\n",
    "    print(\"fetching house details\")\n",
    "    h_list = soup.find_all('h2', class_='heading-6 font-semi-bold nb__1AShY')\n",
    "    h_list = [house.text.strip() for house in h_list]\n",
    "    location = soup.find_all('div',class_=\"nb__2CMjv\")\n",
    "    location = [loc.text.strip() for loc in location]\n",
    "    detail = soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "    detail = [d.text for d in detail]\n",
    "    area = [detail[i] for i in range(len(detail)) if i%3 == 0]\n",
    "    emi = [detail[i+1] for i in range(len(detail)) if i%3 == 0]\n",
    "    price = [detail[i+2] for i in range(len(detail)) if i%3 == 0]\n",
    "    print(\"creating data frame\")\n",
    "    dict = {\"title\":h_list, \"location\": location, \"area\":area, \"EMI\":emi, \"price\":price}\n",
    "    df = pd.DataFrame(dict)\n",
    "    save_csv(df, csv_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ferching data from nobroker\n",
      "fetching house details\n",
      "creating data frame\n",
      "your file xyz.csv has been saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 RK In Independent House  For Sale  In Goregaon</td>\n",
       "      <td>Independent House, Royal Palms, Aarey Colony,N...</td>\n",
       "      <td>150 sqft</td>\n",
       "      <td>₹6,877/Month</td>\n",
       "      <td>₹12 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0  1 RK In Independent House  For Sale  In Goregaon   \n",
       "\n",
       "                                            location      area           EMI  \\\n",
       "0  Independent House, Royal Palms, Aarey Colony,N...  150 sqft  ₹6,877/Month   \n",
       "\n",
       "      price  \n",
       "0  ₹12 Lacs  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_broker(mumbai_url, \"xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ferching data from nobroker\n",
      "fetching house details\n",
      "creating data frame\n",
      "your file no_broker1.csv has been saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Hebba...</td>\n",
       "      <td>Independent House, Bangalore - Hosur Road, Nea...</td>\n",
       "      <td>1,800 sqft</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, surya nagar face 1</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>₹1.43 Lacs/Month</td>\n",
       "      <td>₹2.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, Hosur Rd,Near Infosys Limited</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹42,985/Month</td>\n",
       "      <td>₹75 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Anant...</td>\n",
       "      <td>Independent House, Glass factory Outlet nd cro...</td>\n",
       "      <td>2,200 sqft</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...</td>\n",
       "      <td>Sobha Silicon Oasis Naganathapura, Rayasandra ...</td>\n",
       "      <td>1,879 sqft</td>\n",
       "      <td>₹88,837/Month</td>\n",
       "      <td>₹1.55 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Gopalan Gardenia...</td>\n",
       "      <td>Gopalan Gardenia  Gopalan gardenia, Veerasandr...</td>\n",
       "      <td>2,650 sqft</td>\n",
       "      <td>₹68,777/Month</td>\n",
       "      <td>₹1.2 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 BHK For Sale  In Gpr Royale In Gpr Royale</td>\n",
       "      <td>6th Cross</td>\n",
       "      <td>3,100 sqft</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 BHK Flat  For Sale  In Electronic City</td>\n",
       "      <td>Standalone Building, Shikaripalya near Shams S...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>₹20,060/Month</td>\n",
       "      <td>₹35 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Sarja...</td>\n",
       "      <td>Independent House,  Shantipura Village , S.P L...</td>\n",
       "      <td>1,100 sqft</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Nagan...</td>\n",
       "      <td>Independent House, Doddanagamangala Rd opposit...</td>\n",
       "      <td>1,500 sqft</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  4 BHK In Independent House  For Sale  In Hebba...   \n",
       "1  4 BHK In Independent House  For Sale  In Elect...   \n",
       "2  4 BHK In Independent House  For Sale  In Elect...   \n",
       "3  4 BHK In Independent House  For Sale  In Anant...   \n",
       "4  4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...   \n",
       "5  4 BHK Apartment  For Sale  In Gopalan Gardenia...   \n",
       "6        4 BHK For Sale  In Gpr Royale In Gpr Royale   \n",
       "7           4 BHK Flat  For Sale  In Electronic City   \n",
       "8  4 BHK In Independent House  For Sale  In Sarja...   \n",
       "9  4 BHK In Independent House  For Sale  In Nagan...   \n",
       "\n",
       "                                            location        area  \\\n",
       "0  Independent House, Bangalore - Hosur Road, Nea...  1,800 sqft   \n",
       "1              Independent House, surya nagar face 1  3,000 sqft   \n",
       "2   Independent House, Hosur Rd,Near Infosys Limited  1,200 sqft   \n",
       "3  Independent House, Glass factory Outlet nd cro...  2,200 sqft   \n",
       "4  Sobha Silicon Oasis Naganathapura, Rayasandra ...  1,879 sqft   \n",
       "5  Gopalan Gardenia  Gopalan gardenia, Veerasandr...  2,650 sqft   \n",
       "6                                          6th Cross  3,100 sqft   \n",
       "7  Standalone Building, Shikaripalya near Shams S...  1,400 sqft   \n",
       "8  Independent House,  Shantipura Village , S.P L...  1,100 sqft   \n",
       "9  Independent House, Doddanagamangala Rd opposit...  1,500 sqft   \n",
       "\n",
       "                EMI         price  \n",
       "0     ₹85,971/Month   ₹1.5 Crores  \n",
       "1  ₹1.43 Lacs/Month   ₹2.5 Crores  \n",
       "2     ₹42,985/Month      ₹75 Lacs  \n",
       "3     ₹45,851/Month      ₹80 Lacs  \n",
       "4     ₹88,837/Month  ₹1.55 Crores  \n",
       "5     ₹68,777/Month   ₹1.2 Crores  \n",
       "6     ₹85,971/Month   ₹1.5 Crores  \n",
       "7     ₹20,060/Month      ₹35 Lacs  \n",
       "8     ₹40,120/Month      ₹70 Lacs  \n",
       "9     ₹45,851/Month      ₹80 Lacs  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_broker(banglore_url, \"no_broker1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
